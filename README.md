# ACIF104-Sumativa1-Grupo1
En este repositorio podran encontrar los elementos utilizados en el desarrollo de la actividad Sumativa 1, del curso Aprendizaje de Maquina APTRC106 de la Universidad AndrÃ©s Bello.

# ğŸ’° PredicciÃ³n de Ingresos con Deep Learning (Adult Census Dataset)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![Status](https://img.shields.io/badge/Status-Completado-green)

Este proyecto aborda la problemÃ¡tica de la clasificaciÃ³n de ingresos utilizando el famoso conjunto de datos **Adult Census Income**. El objetivo principal es desarrollar un modelo de Aprendizaje AutomÃ¡tico capaz de predecir si una persona gana mÃ¡s de **$50,000 anuales**, basÃ¡ndose en caracterÃ­sticas demogrÃ¡ficas y laborales.

Este trabajo corresponde a la **EvaluaciÃ³n Sumativa (Fase 2)** del curso de Aprendizaje de MÃ¡quinas.

## ğŸ“‹ Tabla de Contenidos
- [DescripciÃ³n del Problema](#-descripciÃ³n-del-problema)
- [MetodologÃ­a](#-metodologÃ­a)
- [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
- [Resultados Clave](#-resultados-clave)
- [InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso)
- [Estructura del Repositorio](#-estructura-del-repositorio)
- [Autores](#-autores)

## ğŸ§ DescripciÃ³n del Problema
La desigualdad de ingresos y los factores que influyen en ella son temas crÃ­ticos. Utilizando datos del censo de 1994, buscamos construir un modelo predictivo robusto que pueda identificar patrones asociados a altos ingresos.

El desafÃ­o tÃ©cnico principal es el **fuerte desbalance de clases** (solo el ~24% de los registros corresponden a ingresos `>50K`), lo que requiere estrategias especÃ­ficas de modelado y evaluaciÃ³n.

## ğŸš€ MetodologÃ­a
El proyecto sigue un flujo de trabajo de Ciencia de Datos riguroso:

1.  **EDA y Limpieza:** Manejo de valores nulos (`?`), anÃ¡lisis de outliers y eliminaciÃ³n de redundancias (`education` vs `education-num`).
2.  **Preprocesamiento:** Pipeline con `StandardScaler` para numÃ©ricas y `OneHotEncoder` para categÃ³ricas.
3.  **Machine Learning ClÃ¡sico (Baseline):** Comparativa entre RegresiÃ³n LogÃ­stica, Random Forest y SVM.
4.  **Estrategias de Balanceo:** Pruebas con *Baseline*, *SMOTE* y *Class Weights*.
5.  **Deep Learning:** ImplementaciÃ³n y comparaciÃ³n de tres arquitecturas:
    * MLP BÃ¡sico.
    * MLP con RegularizaciÃ³n (Dropout).
    * Arquitectura Wide & Deep.
6.  **Refinamiento:** Ajuste de hiperparÃ¡metros automatizado usando **KerasTuner**.
7.  **Explicabilidad:** AnÃ¡lisis interpretativo del modelo final utilizando **SHAP** (SHapley Additive exPlanations).

## ğŸ›  TecnologÃ­as Utilizadas
* **Python 3**
* **Pandas & NumPy:** ManipulaciÃ³n de datos.
* **Matplotlib & Seaborn:** VisualizaciÃ³n de datos.
* **Scikit-Learn:** Preprocesamiento y modelos clÃ¡sicos.
* **TensorFlow / Keras:** ConstrucciÃ³n de redes neuronales.
* **Keras Tuner:** OptimizaciÃ³n de hiperparÃ¡metros.
* **Imbalanced-learn:** TÃ©cnica SMOTE.
* **SHAP:** Interpretabilidad del modelo.

## ğŸ† Resultados Clave

Tras experimentar con mÃºltiples arquitecturas, el modelo **MLP con Dropout (30%)** resultÃ³ ser el ganador, superando incluso a modelos optimizados automÃ¡ticamente y arquitecturas hÃ­bridas complejas. Esto demostrÃ³ la importancia de la regularizaciÃ³n simple frente al desbalance de datos.

| Modelo | F1-Score (>50K) | AUC-ROC | ConclusiÃ³n |
| :--- | :---: | :---: | :--- |
| **MLP + Dropout (Ganador)** | **0.6836** | **0.9071** | Mejor equilibrio y generalizaciÃ³n. |
| Wide & Deep | 0.6812 | 0.9058 | Muy competitivo, arquitectura robusta. |
| MLP Optimizado (Tuner) | 0.6804 | 0.9070 | Excelente AUC, pero menor F1. |
| MLP BÃ¡sico | 0.6774 | 0.9024 | Buen baseline, tiende al sobreajuste. |

**Insights de SHAP:**
El anÃ¡lisis de interpretabilidad revelÃ³ que el **Estado Civil** (especÃ­ficamente estar casado), la **Edad**, los **AÃ±os de EducaciÃ³n** y las **Ganancias de Capital** son los predictores mÃ¡s fuertes para tener ingresos altos.

## ğŸ’» InstalaciÃ³n y Uso

### EjecuciÃ³n en Google Colab

Si prefieres ejecutar el proyecto en la nube sin instalar nada en tu equipo, sigue estos pasos:

1.  **Abrir el Notebook:**
    Sube el archivo `ACIF104_S6_Grupo13.ipynb` a tu Google Drive y Ã¡brelo con Google Colab, o Ã¡brelo directamente desde GitHub.

2.  **Montar el Repositorio y Cargar el Dataset:**
    Para asegurarte de que el notebook tenga acceso al archivo `adult.csv` y a todos los scripts, ejecuta el siguiente comando en la **primera celda** del notebook:

    ```python
    # Clona el repositorio dentro del entorno de Colab
    !git clone [https://github.com/MaidoniaN/ACIF104-Sumativa1-Grupo1.git](https://github.com/MaidoniaN/ACIF104-Sumativa1-Grupo1.git)

    # Cambia el directorio de trabajo a la carpeta del proyecto
    %cd ACIF104-Sumativa1-Grupo1
    ```
    *Esto descargarÃ¡ automÃ¡ticamente el dataset y los archivos necesarios.*

3.  **Instalar LibrerÃ­as:**
    En una celda siguiente, ejecuta:
    ```python
    !pip install -r requirements.txt
    ```

4.  **Ejecutar Paso a Paso:**
    * Una vez configurado el entorno, ve al menÃº superior **"Entorno de ejecuciÃ³n"** -> **"Ejecutar todas"** para correr el proyecto completo.
    * Alternativamente, presiona `Shift + Enter` en cada celda para ejecutar el anÃ¡lisis secuencialmente y ver los grÃ¡ficos interactivos.


## ğŸ“± AplicaciÃ³n Web (Prototipo Funcional)

Como parte de los requisitos de despliegue, se desarrollÃ³ un prototipo funcional utilizando **Streamlit**. Esta aplicaciÃ³n permite a un usuario interactuar con el modelo final, ingresar nuevos datos y obtener una predicciÃ³n en tiempo real, junto con una explicaciÃ³n de la decisiÃ³n.

### Estructura de la App
* **Backend:** Python + TensorFlow (Carga del modelo `MLP con Dropout`).
* **Frontend:** Interfaz web reactiva construida con Streamlit.
* **XAI:** IntegraciÃ³n de grÃ¡ficos **SHAP** para explicar cada predicciÃ³n individualmente.
* **Monitoreo:** Registro automÃ¡tico de todas las consultas en un archivo `prediction_logs.csv`.

### âš™ï¸ Instrucciones para Ejecutar la App Localmente

Debido a posibles diferencias de versiones entre Google Colab y entornos locales, se incluye un script de "re-entrenamiento ligero" (`entrenar_local.py`) que asegura que los objetos serializados (scalers, encoders) sean compatibles con tu PC.

**1. Preparar el entorno:**
AsegÃºrate de tener el archivo `adult.csv` en la carpeta `API` (o raÃ­z).

```bash
# Crear y activar entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar librerÃ­as
pip install streamlit pandas numpy tensorflow joblib shap matplotlib scikit-learn imbalanced-learn

# Generar Artefactos Locales (Importante): Ejecuta este script para generar el modelo y los preprocesadores compatibles con tu sistema operativo:
python3 entrenar_local.py

# Lanzar la AplicaciÃ³n:
streamlit run app.py

```
### API Corriendo
![API Corriendo](API/API_1.png)

## ğŸ“‚ Estructura del Repositorio

```text
â”œâ”€â”€ ACIF104_S6_Grupo13.ipynb    # Notebook principal con todo el anÃ¡lisis y modelado (Deep Learning)
â”œâ”€â”€ ACIF104_S6_Grupo13.pdf      # Informe final del proyecto (EvaluaciÃ³n Sumativa)
â”œâ”€â”€ requirements.txt            # Lista de dependencias y librerÃ­as necesarias
â”œâ”€â”€ README.md                   # DocumentaciÃ³n del proyecto
â”œâ”€â”€ API/                        # Carpeta de la aplicaciÃ³n web
â”‚   â”œâ”€â”€ app.py                  # CÃ³digo fuente de la aplicaciÃ³n Streamlit (Frontend + Backend)
â”‚   â”œâ”€â”€ adult.csv               # Dataset utilizado por el modelo y la app
â”‚   â”œâ”€â”€ entrenar_local.py       # Script auxiliar para generar modelos compatibles localmente
â”‚   â”œâ”€â”€ modelo_ingresos.keras   # Modelo de Red Neuronal entrenado
â”‚   â”œâ”€â”€ preprocessor.joblib     # Pipeline de preprocesamiento serializado
â”‚   â”œâ”€â”€ shap_background.joblib  # Datos de fondo para explicabilidad SHAP
â”‚   â””â”€â”€ prediction_logs.csv     # Registro (log) de las predicciones realizadas
â””â”€â”€ ACIF104_S6_Grupo13.docx   # Documento editable del informe

```
